# ğŸƒ Leaf AI

**Your private AI assistant, running entirely in your browser**

Leaf AI is a privacy-first, browser-based AI assistant that runs 100% locally using WebGPU. No servers, no tracking, no cloud dependencies - just you and AI, privately.

Built with â¤ï¸ by [the AI Flow Club](https://flow-club.techtiff.ai/)

## âœ¨ Features

- ğŸ”’ **Complete Privacy**: All AI processing happens on your device. No data ever leaves your browser.
- âš¡ **WebGPU Acceleration**: Hardware-accelerated inference using WebGPU for fast responses
- ğŸ“± **Smart Mobile Support**: Optimized for iOS 26+ and Android devices with intelligent model selection based on device capabilities
- ğŸ¤– **Android Optimized**: Three-tier model system automatically detects Android device RAM and recommends compatible models
- ğŸ’¾ **Offline-First**: Works completely offline after initial model download
- ğŸŒ **Multi-language**: English and Spanish support
- ğŸ’¬ **Conversation Management**: Organize chats with folders, tags, and search
- ğŸ“¤ **Export**: Export conversations as Markdown or JSON
- ğŸ¨ **Dark Mode**: Beautiful dark theme support

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+
- npm or yarn

### Installation

```bash
# Clone the repository
git clone https://github.com/dkyazzentwatwa/leaf-ai.git
cd leaf-ai

# Install dependencies
npm install

# Start development server
npm run dev
```

The app will be available at `http://localhost:5173/`

### Available Commands

```bash
npm run dev          # Start dev server
npm run build        # Build for production
npm run preview      # Preview production build
npm run lint         # Run ESLint
npm run test         # Run tests with Vitest
```

## ğŸŒ Browser Compatibility

### Desktop
- âœ… Chrome 113+ (recommended)
- âœ… Edge 113+
- âœ… Brave (latest)
- âœ… Any WebGPU-compatible browser

### Android
- âœ… Chrome 113+ (recommended)
- âœ… Edge 113+
- ğŸ¯ **Smart Model Selection**: Automatically detects device RAM and shows compatible models
  - **Low-end** (< 4GB RAM): Ultra-small models (< 400MB)
  - **Mid-range** (4-6GB RAM): Mobile-optimized models (400MB-2GB) â† **Most Android users**
  - **High-end** (8GB+ RAM): Desktop-class models (1-7GB)

### iOS/iPadOS
- âœ… Safari 26+ / iOS 26+ (WebGPU support)
- âš ï¸ iOS <26: WebGPU not available

**Platform Detection**: Leaf AI automatically detects your device's platform and RAM, showing only models that will work smoothly on your hardware. No more crashes from models that are too large!

## ğŸ§  Available AI Models

Leaf AI uses a **three-tier model system** that automatically adapts to your device:

### ğŸ–¥ï¸ Desktop Tier (2-7GB)
*For high-end Android (8GB+ RAM) and Desktop*
- **Llama 3.2 3B** (~2.3GB) - â­ **Recommended**, best quality (3-7 tok/sec)
- **Qwen3 4B** (~3.4GB) - Latest Qwen, excellent quality (3-5 tok/sec)
- **Llama 3.1 8B** (~4.5GB) - Highest quality, best for powerful desktops (2-4 tok/sec)
- **Mistral 7B v0.3** (~4GB) - Excellent general-purpose model (2-4 tok/sec)

### ğŸ“± Android Tier (400MB-2GB)
*For mid-range Android (4-6GB RAM)*
- **Qwen 2.5 1.5B** (~1GB) - â­ **Recommended for Android**, best quality/size ratio (5-7 tok/sec)
- **Llama 3.2 1B** (~1.1GB) - Compact Meta Llama (5-8 tok/sec)
- **Phi 3.5 Mini** (~1.5GB) - Microsoft's efficient model (4-6 tok/sec)
- **Gemma 2 2B** (~1.9GB) - Google's efficient model (3-6 tok/sec)

### ğŸ iOS Tier (<400MB)
*For iOS 26+ and low-end Android (< 4GB RAM)*
- **SmolLM2 135M** (~360MB, 2-bit) - â­ **Recommended for iOS**, ultra-compact (2-3 tok/sec)
- **SmolLM2 360M** (~376MB, 4-bit) - Small and efficient (2-3 tok/sec)
- **Qwen3 0.6B** (~500MB, 4-bit) - Latest Qwen3 for iOS (2-3 tok/sec)
- **TinyLlama 1.1B** (~697MB, 4-bit) - Better quality (1-2 tok/sec)
- **Qwen 2.5 0.5B** (~945MB, 4-bit) - Quality iOS model (1-2 tok/sec)

**Smart Filtering**: The app automatically shows only models compatible with your device's RAM. Android mid-range users (4-6GB) see 9 models total (iOS + Android tiers), preventing crashes from oversized models.

All models use 4-bit or 2-bit quantization for optimal performance and memory efficiency.

## ğŸ›  Technology Stack

- **Framework**: Vite + React 19 + TypeScript
- **AI Engine**: [WebLLM](https://github.com/mlc-ai/web-llm) (@mlc-ai/web-llm)
- **Acceleration**: WebGPU
- **Styling**: Tailwind CSS + shadcn/ui
- **State Management**: Zustand with localStorage persistence
- **Database**: IndexedDB (Dexie) for conversation history
- **i18n**: i18next + react-i18next (English, Spanish)
- **PWA**: vite-plugin-pwa (Workbox)
- **Router**: React Router v7

## ğŸ— Architecture

### AI Engine Flow

```
User Request
    â†“
ChatInterface (React)
    â†“
useWebLLM (React hook)
    â†“
unifiedEngine (singleton wrapper)
    â†“
workerEngine (Web Worker manager)
    â†“
ai.worker.ts (separate thread)
    â†“
WebLLM (@mlc-ai/web-llm)
    â†“
WebGPU (hardware acceleration)
```

### Key Components

- **`unifiedEngine`**: Main entry point for all AI operations
- **`workerEngine`**: Manages Web Worker communication, device detection, and RAM-based model validation
- **`engine.ts`**: Central model registry with three-tier platform filtering (iOS/Android/Desktop)
- **`aiStore`**: Zustand store for conversations and model state

### Device Detection & Validation

Leaf AI automatically detects:
- **Platform**: iOS, Android, or Desktop
- **RAM**: Uses `navigator.deviceMemory` (Chrome/Edge) or screen-based heuristics
- **Device Tier**: Classifies as low-end (< 4GB), mid-range (4-6GB), or high-end (8GB+)
- **GPU Limits**: Queries WebGPU adapter for buffer size constraints

**Safety Rule**: Models are validated before loading. Android devices can only load models up to 40% of their available RAM, preventing browser crashes.

See [CLAUDE.md](CLAUDE.md) for detailed architecture documentation.

## ğŸ” Privacy Philosophy

Leaf AI is built on these non-negotiable principles:

- âœ… No data sent to external servers
- âœ… No tracking or analytics
- âœ… No user accounts
- âœ… All processing happens locally
- âœ… Open source and auditable

If a feature requires external communication, it doesn't belong in this project.

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ features/ai/           # AI feature module
â”‚   â”œâ”€â”€ components/        # Chat UI, model downloader
â”‚   â”œâ”€â”€ hooks/             # useWebLLM hook
â”‚   â”œâ”€â”€ services/          # AI engine, WebLLM integration
â”‚   â”œâ”€â”€ stores/            # Zustand state management
â”‚   â””â”€â”€ workers/           # Web Workers for AI
â”‚
â”œâ”€â”€ components/            # Shared UI components
â”‚   â”œâ”€â”€ layout/            # Header, footer, layout
â”‚   â””â”€â”€ ui/                # shadcn/ui components
â”‚
â”œâ”€â”€ core/                  # Core infrastructure
â”‚   â”œâ”€â”€ config/            # App configuration
â”‚   â”œâ”€â”€ db/                # IndexedDB schema
â”‚   â””â”€â”€ router/            # React Router setup
â”‚
â”œâ”€â”€ pages/                 # Route pages
â”œâ”€â”€ utils/                 # Utility functions
â””â”€â”€ assets/                # Locales, static assets
```

## ğŸš¢ Deployment

### Required Headers

For WebLLM to work, these headers are **required**:

```
Cross-Origin-Opener-Policy: same-origin
Cross-Origin-Embedder-Policy: require-corp
```

These are configured in:
- `vite.config.ts` (dev/preview)
- `public/_headers` (production - Netlify format)

Without these headers, SharedArrayBuffer and Web Workers will fail.

### Netlify Deployment

1. Push to GitHub
2. Connect to Netlify
3. Build command: `npm run build`
4. Publish directory: `dist`
5. Headers are auto-configured via `public/_headers`

## ğŸ¤ Contributing

Contributions are welcome! Whether it's bug fixes, new features, or documentation improvements.

### Development Guidelines

- Follow the existing code style
- Use TypeScript for all new code
- Mobile-first responsive design (use `sm:`, `md:`, `lg:` breakpoints)
- Add Spanish translations for user-facing text
- Respect the privacy-first philosophy

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details

## ğŸ”— Links

- **GitHub**: [https://github.com/dkyazzentwatwa/leaf-ai](https://github.com/dkyazzentwatwa/leaf-ai)
- **Made by**: [the AI Flow Club](https://flow-club.techtiff.ai/)

---

**Built with â¤ï¸ for a more private world**

Made by [the AI Flow Club](https://flow-club.techtiff.ai/)
